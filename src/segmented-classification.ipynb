{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries and setting environment","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nfrom pathlib import Path\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dropout, Flatten, Dense, Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport warnings\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T12:27:43.398084Z","iopub.execute_input":"2022-12-11T12:27:43.398453Z","iopub.status.idle":"2022-12-11T12:27:53.595813Z","shell.execute_reply.started":"2022-12-11T12:27:43.398423Z","shell.execute_reply":"2022-12-11T12:27:53.594823Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Define functions to load data","metadata":{}},{"cell_type":"code","source":"# Define functions to create a DataFrame with the filepath and the labels of the pictures\ndef proc_img(filepath):\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepath and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    return df\n\n\ndef proc_df(input_dir):\n    path = Path(input_dir)\n    images = os.listdir(input_dir)\n    filepath = [str(path) + '/' + img_path for img_path in images]\n    df = proc_img(filepath)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:27:56.259547Z","iopub.execute_input":"2022-12-11T12:27:56.260257Z","iopub.status.idle":"2022-12-11T12:27:56.281978Z","shell.execute_reply.started":"2022-12-11T12:27:56.260211Z","shell.execute_reply":"2022-12-11T12:27:56.280921Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import datasets\nnormal_df = proc_df(r\"/kaggle/input/segmented-datasets/NORMAL\")\ncovid_df = proc_df(r\"/kaggle/input/segmented-datasets/COVID19\")\npneumonia_df = proc_df(r\"/kaggle/input/segmented-datasets/PNEUMONIA\")\ntb_df = proc_df(r\"/kaggle/input/segmented-datasets/TUBERCULOSIS\")\n\ndataset_df = pd.concat([normal_df, covid_df, pneumonia_df, tb_df])\ndataset_l = len(dataset_df.Label)\nprint(dataset_l)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T08:44:27.392895Z","iopub.execute_input":"2022-12-11T08:44:27.393313Z","iopub.status.idle":"2022-12-11T08:44:27.733443Z","shell.execute_reply.started":"2022-12-11T08:44:27.393277Z","shell.execute_reply":"2022-12-11T08:44:27.732407Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"7132\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dividing train, validation, and test data","metadata":{}},{"cell_type":"code","source":"# extract test data\ntest_df = dataset_df.sample(n=int(dataset_l * 0.1), random_state=1109)\nprint(len(test_df.Label))\n# extract other data\nno_test_df = dataset_df.merge(test_df, how='outer', indicator=True).loc[lambda x: x['_merge'] == 'left_only']\nno_test_df = no_test_df.iloc[:, :2]\n# extract validation data\nvalid_df = no_test_df.sample(n=int(dataset_l * 0.1), random_state=1109)\nprint(len(valid_df))\n# extract training data\ntrain_df = no_test_df.append(valid_df).drop_duplicates(keep=False)\nprint(len(train_df))\n\n# save data\ntest_df.to_csv('/kaggle/working/seg_test_df.csv',sep=',', index=False, header=True)\nvalid_df.to_csv('/kaggle/working/seg_valid_df.csv',sep=',', index=False, header=True)\ntrain_df.to_csv('/kaggle/working/seg_train_df.csv',sep=',', index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T08:46:02.565540Z","iopub.execute_input":"2022-12-11T08:46:02.566415Z","iopub.status.idle":"2022-12-11T08:46:02.615930Z","shell.execute_reply.started":"2022-12-11T08:46:02.566376Z","shell.execute_reply":"2022-12-11T08:46:02.614874Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"713\n713\n5706\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Image generators\n","metadata":{}},{"cell_type":"code","source":"# load data\ntest_df = pd.read_csv('/kaggle/input/models/seg_test_df.csv',sep=',')\nvalid_df = pd.read_csv('/kaggle/input/models/seg_valid_df.csv',sep=',')\ntrain_df = pd.read_csv('/kaggle/input/models/seg_train_df.csv',sep=',')\nprint(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:28:01.433826Z","iopub.execute_input":"2022-12-11T12:28:01.434197Z","iopub.status.idle":"2022-12-11T12:28:01.501456Z","shell.execute_reply.started":"2022-12-11T12:28:01.434167Z","shell.execute_reply":"2022-12-11T12:28:01.500356Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"                                              Filepath         Label\n0    /kaggle/input/segmented-datasets/PNEUMONIA/per...     PNEUMONIA\n1    /kaggle/input/segmented-datasets/COVID19/COVID...       COVID19\n2    /kaggle/input/segmented-datasets/PNEUMONIA/per...     PNEUMONIA\n3    /kaggle/input/segmented-datasets/PNEUMONIA/per...     PNEUMONIA\n4    /kaggle/input/segmented-datasets/TUBERCULOSIS/...  TUBERCULOSIS\n..                                                 ...           ...\n708  /kaggle/input/segmented-datasets/PNEUMONIA/per...     PNEUMONIA\n709  /kaggle/input/segmented-datasets/PNEUMONIA/per...     PNEUMONIA\n710  /kaggle/input/segmented-datasets/NORMAL/NORMAL...        NORMAL\n711  /kaggle/input/segmented-datasets/TUBERCULOSIS/...  TUBERCULOSIS\n712  /kaggle/input/segmented-datasets/NORMAL/NORMAL...        NORMAL\n\n[713 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Image generator\n# Train generator\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\nvalid_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\ntest_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\n\n# Here we used 224 * 224 based on the previous result\ntrain_images = train_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=train_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)\n\nvalid_images = valid_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=valid_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=test_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:28:04.279021Z","iopub.execute_input":"2022-12-11T12:28:04.279386Z","iopub.status.idle":"2022-12-11T12:28:21.553980Z","shell.execute_reply.started":"2022-12-11T12:28:04.279354Z","shell.execute_reply":"2022-12-11T12:28:21.552845Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 5706 validated image filenames belonging to 4 classes.\nFound 713 validated image filenames belonging to 4 classes.\nFound 713 validated image filenames belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model selection\n## Building the models","metadata":{}},{"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:28:25.738465Z","iopub.execute_input":"2022-12-11T12:28:25.738952Z","iopub.status.idle":"2022-12-11T12:28:25.748622Z","shell.execute_reply.started":"2022-12-11T12:28:25.738913Z","shell.execute_reply":"2022-12-11T12:28:25.747718Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# self-designed CNN model\nseg_self_model = Sequential(name=\"self_designed\")\n# convolutions and pooling\nseg_self_model.add(Conv2D(filters=64, strides=1, kernel_size=(5, 5), activation='relu', \n                      input_shape=(224, 224, 1,)))\nseg_self_model.add(MaxPool2D(3, 3))\nseg_self_model.add(Conv2D(filters=30, kernel_size=(3, 3), activation='relu'))\nseg_self_model.add(MaxPool2D(2, 2))\n# flatten\nseg_self_model.add(Flatten())\n# fully-connected\nseg_self_model.add(Dense(1024, activation='relu'))\nseg_self_model.add(Dropout(0.1))\nseg_self_model.add(Dense(256, activation='relu'))\nseg_self_model.add(Dense(64, activation='relu'))\n# output layer\nseg_self_model.add(Dense(16, activation='relu'))\nseg_self_model.add(Dense(4, activation='softmax'))\n# loss function\nseg_self_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nseg_self_model.summary()\n\n# function to create full model with different existing models\ndef create_full_model(base_model, base_model_name, optimizer='adam'):\n    model = Sequential(name=base_model_name)\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(4, activation = 'softmax'))\n    # loss function\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, \n                  metrics=['accuracy'])\n    print(f'{model.summary()}')\n    return model\n\nbase_mobilenet_model = MobileNet(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\nseg_mobilenet_model = create_full_model(base_mobilenet_model, \n                                    \"MobileNet\", \n                                    optimizer='adam')\n\nbase_inceptionresnetv2_model = InceptionResNetV2(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\nseg_inceptionresnetv2_model = create_full_model(base_inceptionresnetv2_model, \n                                            \"InceptionResNetV2\",\n                                            optimizer='adam')\n\nbase_inceptionv3_model = InceptionV3(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\nseg_inceptionv3_model = create_full_model(base_inceptionv3_model, \n                                      \"InceptionV3\",\n                                      optimizer='adam')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:28:29.118835Z","iopub.execute_input":"2022-12-11T12:28:29.119206Z","iopub.status.idle":"2022-12-11T12:28:52.780026Z","shell.execute_reply.started":"2022-12-11T12:28:29.119165Z","shell.execute_reply":"2022-12-11T12:28:52.778998Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"self_designed\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 220, 220, 64)      1664      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 73, 73, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 71, 71, 30)        17310     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 35, 35, 30)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 36750)             0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              37633024  \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               262400    \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                16448     \n_________________________________________________________________\ndense_3 (Dense)              (None, 16)                1040      \n_________________________________________________________________\ndense_4 (Dense)              (None, 4)                 68        \n=================================================================\nTotal params: 37,931,954\nTrainable params: 37,931,954\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"MobileNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228288   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1024)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 4)                 2052      \n=================================================================\nTotal params: 3,755,140\nTrainable params: 3,733,252\nNon-trainable params: 21,888\n_________________________________________________________________\nNone\nModel: \"InceptionResNetV2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_resnet_v2 (Functio (None, 5, 5, 1536)        54336160  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1536)              0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1536)              0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 512)               786944    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 4)                 2052      \n=================================================================\nTotal params: 55,125,156\nTrainable params: 55,064,612\nNon-trainable params: 60,544\n_________________________________________________________________\nNone\nModel: \"InceptionV3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 5, 5, 2048)        21802208  \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 512)               1049088   \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 4)                 2052      \n=================================================================\nTotal params: 22,853,348\nTrainable params: 22,818,916\nNon-trainable params: 34,432\n_________________________________________________________________\nNone\nModel: \"DenseNet121\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Functional)     (None, 7, 7, 1024)        7031232   \n_________________________________________________________________\nglobal_average_pooling2d_3 ( (None, 1024)              0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 512)               524800    \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 4)                 2052      \n=================================================================\nTotal params: 7,558,084\nTrainable params: 7,474,436\nNon-trainable params: 83,648\n_________________________________________________________________\nNone\nModel: \"NASNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nNASNet (Functional)          (None, 7, 7, 4032)        84915090  \n_________________________________________________________________\nglobal_average_pooling2d_4 ( (None, 4032)              0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 4032)              0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 512)               2064896   \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 4)                 2052      \n=================================================================\nTotal params: 86,982,038\nTrainable params: 86,785,370\nNon-trainable params: 196,668\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Additional info","metadata":{}},{"cell_type":"code","source":"# Early stopping and hyperparameters\n# Hyper parameters\nSTEP_SIZE_TRAIN = train_images.n // train_images.batch_size\nSTEP_SIZE_VALID = valid_images.n // valid_images.batch_size\n# Stop the training when there is no improvement after 3 epochs trainings.\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:30:45.158339Z","iopub.execute_input":"2022-12-11T12:30:45.158850Z","iopub.status.idle":"2022-12-11T12:30:45.167348Z","shell.execute_reply.started":"2022-12-11T12:30:45.158807Z","shell.execute_reply":"2022-12-11T12:30:45.166264Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Training the models","metadata":{}},{"cell_type":"code","source":"# self-designed simple CNN model\nseg_self_model_history = seg_self_model.fit(train_images, epochs=20, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nseg_self_model_result = seg_self_model_history.history\nseg_self_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nseg_self_model.save(\"seg_self_model.h5\")\n# save txt\nwith open('seg_self_model_result.txt', 'wb') as file_pi:\n    pickle.dump(seg_self_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T09:56:50.604675Z","iopub.execute_input":"2022-12-11T09:56:50.605393Z","iopub.status.idle":"2022-12-11T10:03:41.452126Z","shell.execute_reply.started":"2022-12-11T09:56:50.605358Z","shell.execute_reply":"2022-12-11T10:03:41.450767Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/20\n179/179 [==============================] - 38s 207ms/step - loss: 1.0062 - accuracy: 0.6048 - val_loss: 0.6877 - val_accuracy: 0.7013\nEpoch 2/20\n179/179 [==============================] - 36s 202ms/step - loss: 0.5555 - accuracy: 0.7822 - val_loss: 0.4700 - val_accuracy: 0.8261\nEpoch 3/20\n179/179 [==============================] - 37s 204ms/step - loss: 0.4375 - accuracy: 0.8332 - val_loss: 0.4354 - val_accuracy: 0.8303\nEpoch 4/20\n179/179 [==============================] - 37s 205ms/step - loss: 0.3422 - accuracy: 0.8708 - val_loss: 0.3342 - val_accuracy: 0.8626\nEpoch 5/20\n179/179 [==============================] - 36s 203ms/step - loss: 0.2895 - accuracy: 0.8894 - val_loss: 0.3552 - val_accuracy: 0.8513\nEpoch 6/20\n179/179 [==============================] - 36s 202ms/step - loss: 0.2522 - accuracy: 0.9076 - val_loss: 0.3067 - val_accuracy: 0.8878\nEpoch 7/20\n179/179 [==============================] - 37s 205ms/step - loss: 0.2245 - accuracy: 0.9161 - val_loss: 0.3299 - val_accuracy: 0.8766\nEpoch 8/20\n179/179 [==============================] - 37s 205ms/step - loss: 0.1916 - accuracy: 0.9299 - val_loss: 0.3579 - val_accuracy: 0.8808\nEpoch 9/20\n179/179 [==============================] - 36s 203ms/step - loss: 0.1666 - accuracy: 0.9350 - val_loss: 0.3234 - val_accuracy: 0.8906\nEpoch 10/20\n179/179 [==============================] - 37s 208ms/step - loss: 0.1483 - accuracy: 0.9441 - val_loss: 0.3351 - val_accuracy: 0.8948\nEpoch 11/20\n179/179 [==============================] - 36s 203ms/step - loss: 0.1370 - accuracy: 0.9501 - val_loss: 0.3299 - val_accuracy: 0.8948\n22/22 [==============================] - 4s 166ms/step - loss: 0.3062 - accuracy: 0.8892\n","output_type":"stream"}]},{"cell_type":"code","source":"# mobilenet\nseg_mobilenet_model_history = seg_mobilenet_model.fit(train_images, epochs=20, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nseg_mobilenet_model_result = seg_mobilenet_model_history.history\nseg_mobilenet_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nseg_mobilenet_model.save(\"seg_mobilenet_model.h5\")\n# save txt\nwith open('seg_mobilenet_model_result.txt', 'wb') as file_pi:\n    pickle.dump(seg_mobilenet_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T10:21:36.246382Z","iopub.execute_input":"2022-12-11T10:21:36.247076Z","iopub.status.idle":"2022-12-11T10:35:52.530034Z","shell.execute_reply.started":"2022-12-11T10:21:36.247039Z","shell.execute_reply":"2022-12-11T10:35:52.529093Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/20\n179/179 [==============================] - 48s 253ms/step - loss: 0.6878 - accuracy: 0.7497 - val_loss: 1.3478 - val_accuracy: 0.6017\nEpoch 2/20\n179/179 [==============================] - 45s 252ms/step - loss: 0.3648 - accuracy: 0.8598 - val_loss: 2.1315 - val_accuracy: 0.6017\nEpoch 3/20\n179/179 [==============================] - 45s 248ms/step - loss: 0.3137 - accuracy: 0.8877 - val_loss: 4.3155 - val_accuracy: 0.0968\nEpoch 4/20\n179/179 [==============================] - 45s 251ms/step - loss: 0.2632 - accuracy: 0.9059 - val_loss: 6.4952 - val_accuracy: 0.0968\nEpoch 5/20\n179/179 [==============================] - 45s 251ms/step - loss: 0.2356 - accuracy: 0.9162 - val_loss: 0.6534 - val_accuracy: 0.8079\nEpoch 6/20\n179/179 [==============================] - 45s 250ms/step - loss: 0.1969 - accuracy: 0.9273 - val_loss: 3.4300 - val_accuracy: 0.4222\nEpoch 7/20\n179/179 [==============================] - 45s 251ms/step - loss: 0.1974 - accuracy: 0.9285 - val_loss: 0.5915 - val_accuracy: 0.8177\nEpoch 8/20\n179/179 [==============================] - 45s 250ms/step - loss: 0.1722 - accuracy: 0.9415 - val_loss: 1.0482 - val_accuracy: 0.6928\nEpoch 9/20\n179/179 [==============================] - 45s 252ms/step - loss: 0.1622 - accuracy: 0.9429 - val_loss: 1.4773 - val_accuracy: 0.7097\nEpoch 10/20\n179/179 [==============================] - 45s 253ms/step - loss: 0.1520 - accuracy: 0.9478 - val_loss: 1.0140 - val_accuracy: 0.7616\nEpoch 11/20\n179/179 [==============================] - 45s 250ms/step - loss: 0.1607 - accuracy: 0.9499 - val_loss: 0.3547 - val_accuracy: 0.8878\nEpoch 12/20\n179/179 [==============================] - 45s 249ms/step - loss: 0.1308 - accuracy: 0.9541 - val_loss: 0.7632 - val_accuracy: 0.7980\nEpoch 13/20\n179/179 [==============================] - 45s 249ms/step - loss: 0.1312 - accuracy: 0.9534 - val_loss: 0.2930 - val_accuracy: 0.8836\nEpoch 14/20\n179/179 [==============================] - 45s 252ms/step - loss: 0.1276 - accuracy: 0.9546 - val_loss: 0.7241 - val_accuracy: 0.8331\nEpoch 15/20\n179/179 [==============================] - 45s 249ms/step - loss: 0.1185 - accuracy: 0.9651 - val_loss: 1.8393 - val_accuracy: 0.6438\nEpoch 16/20\n179/179 [==============================] - 45s 252ms/step - loss: 0.1116 - accuracy: 0.9611 - val_loss: 0.3196 - val_accuracy: 0.9074\nEpoch 17/20\n179/179 [==============================] - 45s 249ms/step - loss: 0.0924 - accuracy: 0.9690 - val_loss: 4.3199 - val_accuracy: 0.3170\nEpoch 18/20\n179/179 [==============================] - 45s 252ms/step - loss: 0.1259 - accuracy: 0.9546 - val_loss: 0.3555 - val_accuracy: 0.9004\n22/22 [==============================] - 4s 178ms/step - loss: 0.2824 - accuracy: 0.8849\n","output_type":"stream"}]},{"cell_type":"code","source":"# inception resnet v2\nseg_inceptionresnetv2_model_history = seg_inceptionresnetv2_model.fit(train_images, epochs=20, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nseg_inceptionresnetv2_model_result = seg_inceptionresnetv2_model_history.history\nseg_inceptionresnetv2_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nseg_inceptionresnetv2_model.save(\"seg_inceptionresnetv2_model.h5\")\nwith open('seg_inceptionresnetv2_model_result.txt', 'wb') as file_pi:\n    pickle.dump(seg_inceptionresnetv2_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T11:14:13.383584Z","iopub.execute_input":"2022-12-11T11:14:13.383946Z","iopub.status.idle":"2022-12-11T11:40:27.580476Z","shell.execute_reply.started":"2022-12-11T11:14:13.383919Z","shell.execute_reply":"2022-12-11T11:40:27.579342Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/20\n179/179 [==============================] - 144s 645ms/step - loss: 0.5523 - accuracy: 0.7971 - val_loss: 1.7055 - val_accuracy: 0.6017\nEpoch 2/20\n179/179 [==============================] - 109s 611ms/step - loss: 0.3327 - accuracy: 0.8726 - val_loss: 16.1920 - val_accuracy: 0.0968\nEpoch 3/20\n179/179 [==============================] - 109s 611ms/step - loss: 0.2852 - accuracy: 0.8926 - val_loss: 11.2212 - val_accuracy: 0.0968\nEpoch 4/20\n179/179 [==============================] - 109s 608ms/step - loss: 0.2330 - accuracy: 0.9176 - val_loss: 9.5168 - val_accuracy: 0.0968\nEpoch 5/20\n179/179 [==============================] - 109s 610ms/step - loss: 0.2183 - accuracy: 0.9218 - val_loss: 0.9693 - val_accuracy: 0.8149\nEpoch 6/20\n179/179 [==============================] - 109s 607ms/step - loss: 0.1991 - accuracy: 0.9301 - val_loss: 0.5320 - val_accuracy: 0.8401\nEpoch 7/20\n179/179 [==============================] - 109s 611ms/step - loss: 0.1961 - accuracy: 0.9278 - val_loss: 2.9321 - val_accuracy: 0.5161\nEpoch 8/20\n179/179 [==============================] - 109s 608ms/step - loss: 0.1769 - accuracy: 0.9373 - val_loss: 3.6046 - val_accuracy: 0.6115\nEpoch 9/20\n179/179 [==============================] - 109s 609ms/step - loss: 0.1606 - accuracy: 0.9443 - val_loss: 0.3292 - val_accuracy: 0.8626\nEpoch 10/20\n179/179 [==============================] - 109s 611ms/step - loss: 0.1529 - accuracy: 0.9458 - val_loss: 18.2181 - val_accuracy: 0.1010\nEpoch 11/20\n179/179 [==============================] - 110s 611ms/step - loss: 0.1363 - accuracy: 0.9532 - val_loss: 7.3652 - val_accuracy: 0.2132\nEpoch 12/20\n179/179 [==============================] - 109s 610ms/step - loss: 0.1218 - accuracy: 0.9541 - val_loss: 17.5020 - val_accuracy: 0.2076\nEpoch 13/20\n179/179 [==============================] - 109s 611ms/step - loss: 0.0947 - accuracy: 0.9686 - val_loss: 6.0829 - val_accuracy: 0.3058\nEpoch 14/20\n179/179 [==============================] - 109s 608ms/step - loss: 0.1382 - accuracy: 0.9523 - val_loss: 6.1888 - val_accuracy: 0.2595\n22/22 [==============================] - 5s 205ms/step - loss: 0.3285 - accuracy: 0.8636\n","output_type":"stream"}]},{"cell_type":"code","source":"# inception v3\nseg_inceptionv3_model_history = seg_inceptionv3_model.fit(train_images, epochs=20, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nseg_inceptionv3_model_result = seg_inceptionv3_model_history.history\nseg_inceptionv3_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nseg_inceptionv3_model.save(\"seg_inceptionv3_model.h5\")\nwith open('seg_inceptionv3_model_result.txt', 'wb') as file_pi:\n    pickle.dump(seg_inceptionv3_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T11:46:48.363103Z","iopub.execute_input":"2022-12-11T11:46:48.364076Z","iopub.status.idle":"2022-12-11T12:03:38.809692Z","shell.execute_reply.started":"2022-12-11T11:46:48.364038Z","shell.execute_reply":"2022-12-11T12:03:38.808577Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/20\n179/179 [==============================] - 100s 436ms/step - loss: 0.6722 - accuracy: 0.7711 - val_loss: 2.8227 - val_accuracy: 0.0968\nEpoch 2/20\n179/179 [==============================] - 51s 286ms/step - loss: 0.3649 - accuracy: 0.8577 - val_loss: 3.1275 - val_accuracy: 0.0940\nEpoch 3/20\n179/179 [==============================] - 51s 286ms/step - loss: 0.3147 - accuracy: 0.8805 - val_loss: 12.7924 - val_accuracy: 0.0968\nEpoch 4/20\n179/179 [==============================] - 52s 288ms/step - loss: 0.3177 - accuracy: 0.8849 - val_loss: 444.4772 - val_accuracy: 0.2076\nEpoch 5/20\n179/179 [==============================] - 52s 289ms/step - loss: 0.3397 - accuracy: 0.8763 - val_loss: 8.5090 - val_accuracy: 0.3422\nEpoch 6/20\n179/179 [==============================] - 51s 284ms/step - loss: 0.2354 - accuracy: 0.9161 - val_loss: 0.3752 - val_accuracy: 0.8626\nEpoch 7/20\n179/179 [==============================] - 51s 287ms/step - loss: 0.2191 - accuracy: 0.9222 - val_loss: 0.3253 - val_accuracy: 0.8920\nEpoch 8/20\n179/179 [==============================] - 52s 287ms/step - loss: 0.1924 - accuracy: 0.9359 - val_loss: 0.4097 - val_accuracy: 0.8724\nEpoch 9/20\n179/179 [==============================] - 51s 284ms/step - loss: 0.2113 - accuracy: 0.9309 - val_loss: 0.1929 - val_accuracy: 0.9327\nEpoch 10/20\n179/179 [==============================] - 51s 286ms/step - loss: 0.1876 - accuracy: 0.9366 - val_loss: 0.3563 - val_accuracy: 0.8682\nEpoch 11/20\n179/179 [==============================] - 52s 289ms/step - loss: 0.1631 - accuracy: 0.9446 - val_loss: 3.6471 - val_accuracy: 0.5344\nEpoch 12/20\n179/179 [==============================] - 51s 283ms/step - loss: 0.1448 - accuracy: 0.9501 - val_loss: 0.6480 - val_accuracy: 0.8135\nEpoch 13/20\n179/179 [==============================] - 52s 288ms/step - loss: 0.1395 - accuracy: 0.9527 - val_loss: 0.1630 - val_accuracy: 0.9439\nEpoch 14/20\n179/179 [==============================] - 51s 283ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.4513 - val_accuracy: 0.8583\nEpoch 15/20\n179/179 [==============================] - 51s 285ms/step - loss: 0.1500 - accuracy: 0.9509 - val_loss: 0.6144 - val_accuracy: 0.8555\nEpoch 16/20\n179/179 [==============================] - 51s 285ms/step - loss: 0.1362 - accuracy: 0.9513 - val_loss: 0.6714 - val_accuracy: 0.8303\nEpoch 17/20\n179/179 [==============================] - 51s 284ms/step - loss: 0.1464 - accuracy: 0.9527 - val_loss: 7.4220 - val_accuracy: 0.4376\nEpoch 18/20\n179/179 [==============================] - 52s 287ms/step - loss: 0.1147 - accuracy: 0.9604 - val_loss: 1.5298 - val_accuracy: 0.7714\n22/22 [==============================] - 4s 193ms/step - loss: 0.1638 - accuracy: 0.9446\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing the models","metadata":{}},{"cell_type":"code","source":"# Load models\nseg_self_model = keras.models.load_model(\"/kaggle/input/models/seg_self_model.h5\")\n\nseg_mobilenet_model = keras.models.load_model(\"/kaggle/input/models/seg_mobilenet_model.h5\")\nseg_inceptionresnetv2_model = keras.models.load_model(\"/kaggle/input/models/seg_inceptionresnetv2_model.h5\")\nseg_inceptionv3_model = keras.models.load_model(\"/kaggle/input/models/seg_inceptionv3_model.h5\")\n\n# Evaluate the label of the test_images\nseg_self_model.evaluate(test_images)\n\nseg_mobilenet_model.evaluate(test_images)\nseg_inceptionresnetv2_model.evaluate(test_images)\nseg_inceptionv3_model.evaluate(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T22:35:43.024750Z","iopub.execute_input":"2022-12-10T22:35:43.025195Z","iopub.status.idle":"2022-12-10T22:37:47.645142Z","shell.execute_reply.started":"2022-12-10T22:35:43.025151Z","shell.execute_reply":"2022-12-10T22:37:47.644021Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"23/23 [==============================] - 25s 571ms/step - loss: 0.2299 - accuracy: 0.9257\n23/23 [==============================] - 9s 375ms/step - loss: 0.2029 - accuracy: 0.9411\n23/23 [==============================] - 15s 443ms/step - loss: 0.2570 - accuracy: 0.9116\n23/23 [==============================] - 11s 412ms/step - loss: 0.1511 - accuracy: 0.9537\n23/23 [==============================] - 14s 454ms/step - loss: 0.1840 - accuracy: 0.9467\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[0.18400059640407562, 0.946704089641571]"},"metadata":{}}]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries and setting environment","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nfrom pathlib import Path\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dropout, Flatten, Dense, Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport warnings\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-10T22:31:28.298853Z","iopub.execute_input":"2022-12-10T22:31:28.299481Z","iopub.status.idle":"2022-12-10T22:31:28.306524Z","shell.execute_reply.started":"2022-12-10T22:31:28.299442Z","shell.execute_reply":"2022-12-10T22:31:28.305550Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Define functions to load data","metadata":{}},{"cell_type":"code","source":"# Define functions to create a DataFrame with the filepath and the labels of the pictures\ndef proc_img(filepath):\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepath and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    return df\n\n\ndef proc_df(input_dir):\n    path = Path(input_dir)\n    images = os.listdir(input_dir)\n    filepath = [str(path) + '/' + img_path for img_path in images]\n    df = proc_img(filepath)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-10T22:31:33.607435Z","iopub.execute_input":"2022-12-10T22:31:33.607824Z","iopub.status.idle":"2022-12-10T22:31:33.616204Z","shell.execute_reply.started":"2022-12-10T22:31:33.607782Z","shell.execute_reply":"2022-12-10T22:31:33.615099Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import datasets\nnormal_df = proc_df(r\"/kaggle/input/yihui-data/dataset/NORMAL\")\ncovid_df = proc_df(r\"/kaggle/input/yihui-data/dataset/COVID19\")\npneumonia_df = proc_df(r\"/kaggle/input/yihui-data/dataset/PNEUMONIA\")\ntb_df = proc_df(r\"/kaggle/input/yihui-data/dataset/TUBERCULOSIS\")\n\ndataset_df = pd.concat([normal_df, covid_df, pneumonia_df, tb_df])\ndataset_l = len(dataset_df.Label)\nprint(dataset_l)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T17:10:14.831212Z","iopub.execute_input":"2022-12-10T17:10:14.831713Z","iopub.status.idle":"2022-12-10T17:10:15.533385Z","shell.execute_reply.started":"2022-12-10T17:10:14.831670Z","shell.execute_reply":"2022-12-10T17:10:15.532341Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"7132\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dividing train, validation, and test data","metadata":{}},{"cell_type":"code","source":"# extract test data\ntest_df = dataset_df.sample(n=int(dataset_l * 0.1), random_state=1109)\nprint(len(test_df.Label))\n# extract other data\nno_test_df = dataset_df.merge(test_df, how='outer', indicator=True).loc[lambda x: x['_merge'] == 'left_only']\nno_test_df = no_test_df.iloc[:, :2]\n# extract validation data\nvalid_df = no_test_df.sample(n=int(dataset_l * 0.1), random_state=1109)\nprint(len(valid_df))\n# extract training data\ntrain_df = no_test_df.append(valid_df).drop_duplicates(keep=False)\nprint(len(train_df))\n\n# save data\ntest_df.to_csv('/kaggle/working/test_df.csv',sep=',', index=False, header=True)\nvalid_df.to_csv('/kaggle/working/valid_df.csv',sep=',', index=False, header=True)\ntrain_df.to_csv('/kaggle/working/train_df.csv',sep=',', index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T17:10:19.498923Z","iopub.execute_input":"2022-12-10T17:10:19.499607Z","iopub.status.idle":"2022-12-10T17:10:19.562707Z","shell.execute_reply.started":"2022-12-10T17:10:19.499569Z","shell.execute_reply":"2022-12-10T17:10:19.558750Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"713\n713\n5706\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Image generators\n","metadata":{}},{"cell_type":"code","source":"# load data\ntest_df = pd.read_csv('/kaggle/input/models/test_df.csv',sep=',')\nvalid_df = pd.read_csv('/kaggle/input/models/valid_df.csv',sep=',')\ntrain_df = pd.read_csv('/kaggle/input/models/train_df.csv',sep=',')\nprint(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T22:34:11.568968Z","iopub.execute_input":"2022-12-10T22:34:11.569358Z","iopub.status.idle":"2022-12-10T22:34:11.635274Z","shell.execute_reply.started":"2022-12-10T22:34:11.569296Z","shell.execute_reply":"2022-12-10T22:34:11.634196Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                              Filepath         Label\n0    /kaggle/input/yihui-data/dataset/PNEUMONIA/per...     PNEUMONIA\n1    /kaggle/input/yihui-data/dataset/COVID19/COVID...       COVID19\n2    /kaggle/input/yihui-data/dataset/PNEUMONIA/per...     PNEUMONIA\n3    /kaggle/input/yihui-data/dataset/PNEUMONIA/per...     PNEUMONIA\n4    /kaggle/input/yihui-data/dataset/TUBERCULOSIS/...  TUBERCULOSIS\n..                                                 ...           ...\n708  /kaggle/input/yihui-data/dataset/PNEUMONIA/per...     PNEUMONIA\n709  /kaggle/input/yihui-data/dataset/PNEUMONIA/per...     PNEUMONIA\n710  /kaggle/input/yihui-data/dataset/NORMAL/IM-059...        NORMAL\n711  /kaggle/input/yihui-data/dataset/TUBERCULOSIS/...  TUBERCULOSIS\n712  /kaggle/input/yihui-data/dataset/NORMAL/NORMAL...        NORMAL\n\n[713 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Image generator\n# Train generator\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\nvalid_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\ntest_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1. / 255\n)\n\n# Here we used 224 * 224 based on the previous result\ntrain_images = train_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=train_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)\n\nvalid_images = valid_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=valid_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    x_col='Filepath',\n    y_col='Label',\n    dataframe=test_df,\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True, seed=1109\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T22:35:13.729959Z","iopub.execute_input":"2022-12-10T22:35:13.730352Z","iopub.status.idle":"2022-12-10T22:35:31.385420Z","shell.execute_reply.started":"2022-12-10T22:35:13.730293Z","shell.execute_reply":"2022-12-10T22:35:31.384388Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 5706 validated image filenames belonging to 4 classes.\nFound 713 validated image filenames belonging to 4 classes.\nFound 713 validated image filenames belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model selection\n## Building the models","metadata":{}},{"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2022-12-10T21:50:48.785312Z","iopub.execute_input":"2022-12-10T21:50:48.785690Z","iopub.status.idle":"2022-12-10T21:50:48.793507Z","shell.execute_reply.started":"2022-12-10T21:50:48.785660Z","shell.execute_reply":"2022-12-10T21:50:48.792600Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# self-designed CNN model\nself_model = Sequential(name=\"self_designed\")\n# convolutions and pooling\nself_model.add(Conv2D(filters=64, strides=1, kernel_size=(5, 5), activation='relu', \n                      input_shape=(224, 224, 1,)))\nself_model.add(MaxPool2D(3, 3))\nself_model.add(Conv2D(filters=30, kernel_size=(3, 3), activation='relu'))\nself_model.add(MaxPool2D(2, 2))\n# flatten\nself_model.add(Flatten())\n# fully-connected\nself_model.add(Dense(1024, activation='relu'))\nself_model.add(Dropout(0.1))\nself_model.add(Dense(256, activation='relu'))\nself_model.add(Dense(64, activation='relu'))\n# output layer\nself_model.add(Dense(16, activation='relu'))\nself_model.add(Dense(4, activation='softmax'))\n# loss function\nself_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nself_model.summary()\n\n# function to create full model with different existing models\ndef create_full_model(base_model, base_model_name, optimizer='adam'):\n    model = Sequential(name=base_model_name)\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(4, activation = 'softmax'))\n    # loss function\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, \n                  metrics=['accuracy'])\n    print(f'{model.summary()}')\n    return model\n\nbase_mobilenet_model = MobileNet(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\nmobilenet_model = create_full_model(base_mobilenet_model, \n                                    \"MobileNet\", \n                                    optimizer='adam')\n\nbase_inceptionresnetv2_model = InceptionResNetV2(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\ninceptionresnetv2_model = create_full_model(base_inceptionresnetv2_model, \n                                            \"InceptionResNetV2\",\n                                            optimizer='adam')\n\nbase_inceptionv3_model = InceptionV3(input_shape=(224, 224, 1,), \n                                 include_top = False, weights = None)\ninceptionv3_model = create_full_model(base_inceptionv3_model, \n                                      \"InceptionV3\",\n                                      optimizer='adam')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-10T21:51:19.609053Z","iopub.execute_input":"2022-12-10T21:51:19.609445Z","iopub.status.idle":"2022-12-10T21:51:38.617980Z","shell.execute_reply.started":"2022-12-10T21:51:19.609404Z","shell.execute_reply":"2022-12-10T21:51:38.616917Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model: \"self_designed\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3293 (Conv2D)         (None, 220, 220, 64)      1664      \n_________________________________________________________________\nmax_pooling2d_114 (MaxPoolin (None, 73, 73, 64)        0         \n_________________________________________________________________\nconv2d_3294 (Conv2D)         (None, 71, 71, 30)        17310     \n_________________________________________________________________\nmax_pooling2d_115 (MaxPoolin (None, 35, 35, 30)        0         \n_________________________________________________________________\nflatten_25 (Flatten)         (None, 36750)             0         \n_________________________________________________________________\ndense_260 (Dense)            (None, 1024)              37633024  \n_________________________________________________________________\ndropout_105 (Dropout)        (None, 1024)              0         \n_________________________________________________________________\ndense_261 (Dense)            (None, 256)               262400    \n_________________________________________________________________\ndense_262 (Dense)            (None, 64)                16448     \n_________________________________________________________________\ndense_263 (Dense)            (None, 16)                1040      \n_________________________________________________________________\ndense_264 (Dense)            (None, 4)                 68        \n=================================================================\nTotal params: 37,931,954\nTrainable params: 37,931,954\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"MobileNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228288   \n_________________________________________________________________\nglobal_average_pooling2d_50  (None, 1024)              0         \n_________________________________________________________________\ndropout_106 (Dropout)        (None, 1024)              0         \n_________________________________________________________________\ndense_265 (Dense)            (None, 512)               524800    \n_________________________________________________________________\ndropout_107 (Dropout)        (None, 512)               0         \n_________________________________________________________________\ndense_266 (Dense)            (None, 4)                 2052      \n=================================================================\nTotal params: 3,755,140\nTrainable params: 3,733,252\nNon-trainable params: 21,888\n_________________________________________________________________\nNone\nModel: \"InceptionResNetV2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_resnet_v2 (Functio (None, 5, 5, 1536)        54336160  \n_________________________________________________________________\nglobal_average_pooling2d_51  (None, 1536)              0         \n_________________________________________________________________\ndropout_108 (Dropout)        (None, 1536)              0         \n_________________________________________________________________\ndense_267 (Dense)            (None, 512)               786944    \n_________________________________________________________________\ndropout_109 (Dropout)        (None, 512)               0         \n_________________________________________________________________\ndense_268 (Dense)            (None, 4)                 2052      \n=================================================================\nTotal params: 55,125,156\nTrainable params: 55,064,612\nNon-trainable params: 60,544\n_________________________________________________________________\nNone\nModel: \"InceptionV3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 5, 5, 2048)        21802208  \n_________________________________________________________________\nglobal_average_pooling2d_52  (None, 2048)              0         \n_________________________________________________________________\ndropout_110 (Dropout)        (None, 2048)              0         \n_________________________________________________________________\ndense_269 (Dense)            (None, 512)               1049088   \n_________________________________________________________________\ndropout_111 (Dropout)        (None, 512)               0         \n_________________________________________________________________\ndense_270 (Dense)            (None, 4)                 2052      \n=================================================================\nTotal params: 22,853,348\nTrainable params: 22,818,916\nNon-trainable params: 34,432\n_________________________________________________________________\nNone\nModel: \"DenseNet121\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Functional)     (None, 7, 7, 1024)        7031232   \n_________________________________________________________________\nglobal_average_pooling2d_53  (None, 1024)              0         \n_________________________________________________________________\ndropout_112 (Dropout)        (None, 1024)              0         \n_________________________________________________________________\ndense_271 (Dense)            (None, 512)               524800    \n_________________________________________________________________\ndropout_113 (Dropout)        (None, 512)               0         \n_________________________________________________________________\ndense_272 (Dense)            (None, 4)                 2052      \n=================================================================\nTotal params: 7,558,084\nTrainable params: 7,474,436\nNon-trainable params: 83,648\n_________________________________________________________________\nNone\nModel: \"NASNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nNASNet (Functional)          (None, 7, 7, 4032)        84915090  \n_________________________________________________________________\nglobal_average_pooling2d_54  (None, 4032)              0         \n_________________________________________________________________\ndropout_114 (Dropout)        (None, 4032)              0         \n_________________________________________________________________\ndense_273 (Dense)            (None, 512)               2064896   \n_________________________________________________________________\ndropout_115 (Dropout)        (None, 512)               0         \n_________________________________________________________________\ndense_274 (Dense)            (None, 4)                 2052      \n=================================================================\nTotal params: 86,982,038\nTrainable params: 86,785,370\nNon-trainable params: 196,668\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Additional info","metadata":{}},{"cell_type":"code","source":"# Early stopping and hyperparameters\n# Hyper parameters\nSTEP_SIZE_TRAIN = train_images.n // train_images.batch_size\nSTEP_SIZE_VALID = valid_images.n // valid_images.batch_size\n# Stop the training when there is no improvement after 3 epochs trainings.\nearly_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T17:11:15.627594Z","iopub.execute_input":"2022-12-10T17:11:15.628014Z","iopub.status.idle":"2022-12-10T17:11:15.633674Z","shell.execute_reply.started":"2022-12-10T17:11:15.627975Z","shell.execute_reply":"2022-12-10T17:11:15.632705Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Training the models","metadata":{}},{"cell_type":"code","source":"# self-designed simple CNN model\nself_model_history = self_model.fit(train_images, epochs=10, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nself_model_result = self_model_history.history\nself_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nself_model.save(\"self_model.h5\")\n# save txt\nwith open('self_model_result.txt', 'wb') as file_pi:\n    pickle.dump(self_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T17:11:19.239867Z","iopub.execute_input":"2022-12-10T17:11:19.240243Z","iopub.status.idle":"2022-12-10T17:25:48.438293Z","shell.execute_reply.started":"2022-12-10T17:11:19.240211Z","shell.execute_reply":"2022-12-10T17:25:48.437296Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n179/179 [==============================] - 127s 655ms/step - loss: 0.8054 - accuracy: 0.6942 - val_loss: 0.3835 - val_accuracy: 0.8541\nEpoch 2/10\n179/179 [==============================] - 82s 457ms/step - loss: 0.3641 - accuracy: 0.8621 - val_loss: 0.2826 - val_accuracy: 0.8976\nEpoch 3/10\n179/179 [==============================] - 82s 457ms/step - loss: 0.2908 - accuracy: 0.8920 - val_loss: 0.3082 - val_accuracy: 0.8892\nEpoch 4/10\n179/179 [==============================] - 81s 453ms/step - loss: 0.2475 - accuracy: 0.9152 - val_loss: 0.2470 - val_accuracy: 0.9116\nEpoch 5/10\n179/179 [==============================] - 81s 454ms/step - loss: 0.2251 - accuracy: 0.9185 - val_loss: 0.2109 - val_accuracy: 0.9187\nEpoch 6/10\n179/179 [==============================] - 80s 448ms/step - loss: 0.1952 - accuracy: 0.9269 - val_loss: 0.2097 - val_accuracy: 0.9088\nEpoch 7/10\n179/179 [==============================] - 81s 453ms/step - loss: 0.1792 - accuracy: 0.9371 - val_loss: 0.2241 - val_accuracy: 0.9158\nEpoch 8/10\n179/179 [==============================] - 81s 450ms/step - loss: 0.1626 - accuracy: 0.9450 - val_loss: 0.1924 - val_accuracy: 0.9285\nEpoch 9/10\n179/179 [==============================] - 81s 451ms/step - loss: 0.1529 - accuracy: 0.9441 - val_loss: 0.2514 - val_accuracy: 0.9130\nEpoch 10/10\n179/179 [==============================] - 81s 454ms/step - loss: 0.1406 - accuracy: 0.9494 - val_loss: 0.1713 - val_accuracy: 0.9411\n22/22 [==============================] - 8s 382ms/step - loss: 0.1682 - accuracy: 0.9418\n","output_type":"stream"}]},{"cell_type":"code","source":"# mobilenet\nmobilenet_model_history = mobilenet_model.fit(train_images, epochs=10, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\nmobilenet_model_result = mobilenet_model_history.history\nmobilenet_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\nmobilenet_model.save(\"mobilenet_model.h5\")\n# save txt\nwith open('mobilenet_model_result.txt', 'wb') as file_pi:\n    pickle.dump(mobilenet_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:04:45.672736Z","iopub.execute_input":"2022-12-10T18:04:45.673123Z","iopub.status.idle":"2022-12-10T18:16:38.143542Z","shell.execute_reply.started":"2022-12-10T18:04:45.673089Z","shell.execute_reply":"2022-12-10T18:16:38.140938Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/10\n179/179 [==============================] - 91s 494ms/step - loss: 0.9777 - accuracy: 0.7345 - val_loss: 2.2434 - val_accuracy: 0.0940\nEpoch 2/10\n179/179 [==============================] - 87s 483ms/step - loss: 0.3810 - accuracy: 0.8705 - val_loss: 2.3200 - val_accuracy: 0.0968\nEpoch 3/10\n179/179 [==============================] - 88s 490ms/step - loss: 0.2529 - accuracy: 0.9092 - val_loss: 1.9129 - val_accuracy: 0.6017\nEpoch 4/10\n179/179 [==============================] - 87s 485ms/step - loss: 0.2253 - accuracy: 0.9213 - val_loss: 1.8110 - val_accuracy: 0.6311\nEpoch 5/10\n179/179 [==============================] - 88s 487ms/step - loss: 0.1858 - accuracy: 0.9341 - val_loss: 0.6854 - val_accuracy: 0.7868\nEpoch 6/10\n179/179 [==============================] - 87s 488ms/step - loss: 0.1594 - accuracy: 0.9436 - val_loss: 0.2219 - val_accuracy: 0.9257\nEpoch 7/10\n179/179 [==============================] - 87s 486ms/step - loss: 0.1337 - accuracy: 0.9511 - val_loss: 0.3993 - val_accuracy: 0.8738\nEpoch 8/10\n179/179 [==============================] - 88s 490ms/step - loss: 0.1372 - accuracy: 0.9522 - val_loss: 1.1669 - val_accuracy: 0.7265\n22/22 [==============================] - 9s 391ms/step - loss: 0.2221 - accuracy: 0.9261\n","output_type":"stream"}]},{"cell_type":"code","source":"# inception resnet v2\ninceptionresnetv2_model_history = inceptionresnetv2_model.fit(train_images, epochs=10, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\ninceptionresnetv2_model_result = inceptionresnetv2_model_history.history\ninceptionresnetv2_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\ninceptionresnetv2_model.save(\"inceptionresnetv2_model.h5\")\nwith open('inceptionresnetv2_model_result.txt', 'wb') as file_pi:\n    pickle.dump(inceptionresnetv2_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T19:22:30.899660Z","iopub.execute_input":"2022-12-10T19:22:30.900026Z","iopub.status.idle":"2022-12-10T19:37:43.196034Z","shell.execute_reply.started":"2022-12-10T19:22:30.899994Z","shell.execute_reply":"2022-12-10T19:37:43.194549Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/10\n179/179 [==============================] - 142s 701ms/step - loss: 0.5705 - accuracy: 0.8058 - val_loss: 5.4373 - val_accuracy: 0.0968\nEpoch 2/10\n179/179 [==============================] - 122s 682ms/step - loss: 0.3111 - accuracy: 0.8919 - val_loss: 1.8240 - val_accuracy: 0.6283\nEpoch 3/10\n179/179 [==============================] - 122s 682ms/step - loss: 0.2684 - accuracy: 0.9085 - val_loss: 2.1089 - val_accuracy: 0.5877\nEpoch 4/10\n179/179 [==============================] - 123s 682ms/step - loss: 0.2203 - accuracy: 0.9236 - val_loss: 0.6571 - val_accuracy: 0.8191\nEpoch 5/10\n179/179 [==============================] - 123s 682ms/step - loss: 0.1954 - accuracy: 0.9329 - val_loss: 0.2379 - val_accuracy: 0.9032\nEpoch 6/10\n179/179 [==============================] - 123s 686ms/step - loss: 0.1740 - accuracy: 0.9373 - val_loss: 0.3757 - val_accuracy: 0.8864\nEpoch 7/10\n179/179 [==============================] - 122s 680ms/step - loss: 0.1624 - accuracy: 0.9425 - val_loss: 0.3722 - val_accuracy: 0.8850\n22/22 [==============================] - 10s 455ms/step - loss: 0.2402 - accuracy: 0.9020\n","output_type":"stream"}]},{"cell_type":"code","source":"# inception v3\ninceptionv3_model_history = inceptionv3_model.fit(train_images, epochs=10, validation_data=valid_images, verbose=1, \n                    callbacks = early_stop)\ninceptionv3_model_result = inceptionv3_model_history.history\ninceptionv3_model.evaluate(valid_images, steps=STEP_SIZE_VALID) # Evaluate the model\ninceptionv3_model.save(\"inceptionv3_model.h5\")\nwith open('inceptionv3_model_result.txt', 'wb') as file_pi:\n    pickle.dump(inceptionv3_model_result, file_pi)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T19:41:33.638194Z","iopub.execute_input":"2022-12-10T19:41:33.638573Z","iopub.status.idle":"2022-12-10T19:57:03.098307Z","shell.execute_reply.started":"2022-12-10T19:41:33.638543Z","shell.execute_reply":"2022-12-10T19:57:03.097223Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/10\n179/179 [==============================] - 98s 515ms/step - loss: 0.7941 - accuracy: 0.7648 - val_loss: 3.4717 - val_accuracy: 0.6017\nEpoch 2/10\n179/179 [==============================] - 91s 504ms/step - loss: 0.3926 - accuracy: 0.8651 - val_loss: 2.3819 - val_accuracy: 0.6017\nEpoch 3/10\n179/179 [==============================] - 91s 506ms/step - loss: 0.2939 - accuracy: 0.8998 - val_loss: 4.7865 - val_accuracy: 0.0982\nEpoch 4/10\n179/179 [==============================] - 91s 506ms/step - loss: 0.2729 - accuracy: 0.9033 - val_loss: 1.4303 - val_accuracy: 0.7223\nEpoch 5/10\n179/179 [==============================] - 91s 507ms/step - loss: 0.2370 - accuracy: 0.9206 - val_loss: 0.2787 - val_accuracy: 0.9173\nEpoch 6/10\n179/179 [==============================] - 90s 505ms/step - loss: 0.1907 - accuracy: 0.9343 - val_loss: 0.1805 - val_accuracy: 0.9369\nEpoch 7/10\n179/179 [==============================] - 90s 500ms/step - loss: 0.1759 - accuracy: 0.9432 - val_loss: 0.1662 - val_accuracy: 0.9467\nEpoch 8/10\n179/179 [==============================] - 92s 513ms/step - loss: 0.1639 - accuracy: 0.9453 - val_loss: 0.1477 - val_accuracy: 0.9453\nEpoch 9/10\n179/179 [==============================] - 92s 515ms/step - loss: 0.1611 - accuracy: 0.9441 - val_loss: 0.2112 - val_accuracy: 0.9383\nEpoch 10/10\n179/179 [==============================] - 91s 507ms/step - loss: 0.1434 - accuracy: 0.9525 - val_loss: 0.3521 - val_accuracy: 0.8654\n22/22 [==============================] - 9s 406ms/step - loss: 0.1491 - accuracy: 0.9446\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing the models","metadata":{}},{"cell_type":"code","source":"self_model = keras.models.load_model(\"/kaggle/input/models/self_model.h5\")\nmobilenet_model = keras.models.load_model(\"/kaggle/input/models/mobilenet_model.h5\")\ninceptionresnetv2_model = keras.models.load_model(\"/kaggle/input/models/inceptionresnetv2_model.h5\")\ninceptionv3_model = keras.models.load_model(\"/kaggle/input/models/inceptionv3_model.h5\")\ndensenet121_model = keras.models.load_model(\"/kaggle/input/models/densenet121_model.h5\")\n\n# Evaluate the label of the test_images\nself_model.evaluate(test_images)\nmobilenet_model.evaluate(test_images)\ninceptionresnetv2_model.evaluate(test_images)\ninceptionv3_model.evaluate(test_images)\ndensenet121_model.evaluate(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T22:35:43.024750Z","iopub.execute_input":"2022-12-10T22:35:43.025195Z","iopub.status.idle":"2022-12-10T22:37:47.645142Z","shell.execute_reply.started":"2022-12-10T22:35:43.025151Z","shell.execute_reply":"2022-12-10T22:37:47.644021Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"23/23 [==============================] - 25s 571ms/step - loss: 0.2299 - accuracy: 0.9257\n23/23 [==============================] - 9s 375ms/step - loss: 0.2029 - accuracy: 0.9411\n23/23 [==============================] - 15s 443ms/step - loss: 0.2570 - accuracy: 0.9116\n23/23 [==============================] - 11s 412ms/step - loss: 0.1511 - accuracy: 0.9537\n23/23 [==============================] - 14s 454ms/step - loss: 0.1840 - accuracy: 0.9467\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[0.18400059640407562, 0.946704089641571]"},"metadata":{}}]}]}